{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"parse_dxml_files.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4PMIpvnPJIw2"},"source":["#Common Setting"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3BBALIQxKv9j","executionInfo":{"status":"ok","timestamp":1626837521905,"user_tz":240,"elapsed":182,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}},"outputId":"2f26c6b5-2933-4bf6-cbcb-116891053e23"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":138,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RSAWKgqFNcwG","executionInfo":{"status":"ok","timestamp":1626840024189,"user_tz":240,"elapsed":186,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}},"outputId":"3f2048bd-a280-4119-cf0a-f3e6a1d83003"},"source":["%cd /content/drive/MyDrive/security_mft"],"execution_count":183,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/GitHub/security_mft\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpTeUd90NeMO","executionInfo":{"status":"ok","timestamp":1626840025468,"user_tz":240,"elapsed":233,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}},"outputId":"4204872c-225c-424c-8841-543da7043d0d"},"source":["%pwd\n","%ls"],"execution_count":184,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mcode\u001b[0m/  \u001b[01;34mdfxml_files\u001b[0m/  \u001b[01;34mMFT_files\u001b[0m/  README.md  \u001b[01;34mresident_files\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W0KnoopnOEYm","executionInfo":{"status":"ok","timestamp":1626840026337,"user_tz":240,"elapsed":172,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}}},"source":["import pandas as pd\n","import numpy as np\n","import os\n","import glob\n","import sys\n","import hashlib\n","import re\n","from datetime import datetime\n","import time\n","\n","import xml.etree.ElementTree as ET\n"],"execution_count":185,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxqAGeiwNnws","executionInfo":{"status":"ok","timestamp":1626840027989,"user_tz":240,"elapsed":186,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}}},"source":["start_time = datetime.now()\n","mode = \"test\" #run or test\n","env = 1 # 1- google colab,  else - local\n","if(env == 1):\n","  pathToDxml = \"/content/drive/MyDrive/security_mft/dfxml_files\"\n","else:\n","  pathToDxml = \".\"\n","\n"],"execution_count":186,"outputs":[]},{"cell_type":"code","metadata":{"id":"icxbbjZgMBpJ","executionInfo":{"status":"ok","timestamp":1626837522370,"user_tz":240,"elapsed":19,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}}},"source":["# def getTag(tree):\n","#   tree = ET.parse('first_second.dfxml')\n","#   tagList = []\n","#   for elem in tree.iter():\n","#     tagList.append(re.sub(r\"\\{[^()]*\\}\", \"\", elem.tag))\n","#   #tagList = list(set(tagList))\n","#   return tagList"],"execution_count":143,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PWGq8KWlltdw","executionInfo":{"status":"ok","timestamp":1626840030560,"user_tz":240,"elapsed":178,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}},"outputId":"5ff349a2-1c56-4f9b-9b7a-f9095cd7152e"},"source":["#test 1\n","s = '{http://www.forensicswiki.org/wiki/Category:Digital_Forensics_XML}gid'\n","s = re.sub(r'{.+}', '', s)\n","print(f\"after: {s}\")"],"execution_count":187,"outputs":[{"output_type":"stream","text":["after: gid\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DYQWdZeTJPxF"},"source":["#Method 1 ElementTree"]},{"cell_type":"code","metadata":{"id":"HksYrAxIPw9k","executionInfo":{"status":"ok","timestamp":1626837522371,"user_tz":240,"elapsed":18,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}}},"source":["def parseDxml(pathToFile):\n","  start_time = datetime.now()\n","\n","  tree = ET.parse(pathToFile)\n","  root = tree.getroot()\n","  df = showInfo(root)\n","  csv_filename = f\"{pathToDxml}/parse_result_{os.path.basename(pathToFile)[:-6]}.csv\"\n","  df.to_csv (csv_filename, index = False, header=True)\n","\n","  end_time = datetime.now()\n","  print(f\"Duration of parsing data for {os.path.basename(pathToFile)[:-6]}: {end_time - start_time}\")\n","\n"],"execution_count":145,"outputs":[]},{"cell_type":"code","metadata":{"id":"udTWbGZnjnUn","executionInfo":{"status":"ok","timestamp":1626837522371,"user_tz":240,"elapsed":17,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}}},"source":["import re\n","\n","# #test 1\n","# s = '{http://www.forensicswiki.org/wiki/Category:Digital_Forensics_XML}gid'\n","# s = re.sub(r'{.+}', '', s)\n","# print(f\"after: {s}\")\n","\n","# #test 2\n","# s = '<@ \"\"\"@$ FSDF >something something <more noise>'\n","# s = re.sub(r'<.+>', '',s)\n","# # s = re.sub('<[^>]+>', '', s)\n","# print(f\"after: {s}\")\n","\n","def rename(s):\n","  s = re.sub(r'{.+}', '', s)\n","  # print(s)\n","  return s"],"execution_count":146,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9h-J9LXOREwL","executionInfo":{"status":"ok","timestamp":1626837522379,"user_tz":240,"elapsed":24,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}},"outputId":"101f4969-ce79-43d2-a3f9-d46285f15407"},"source":["def updt(total, progress):\n","    \"\"\"\n","    Displays or updates a console progress bar.\n","\n","    Original source: https://stackoverflow.com/a/15860757/1391441\n","    \"\"\"\n","    barLength, status = 20, \"\"\n","    progress = float(progress) / float(total)\n","    if progress >= 1.:\n","        progress, status = 1, \"\\r\\n\"\n","    block = int(round(barLength * progress))\n","    text = \"\\r[{}] {:.0f}% {}\".format(\n","        \"#\" * block + \"-\" * (barLength - block), round(progress * 100, 0),\n","        status)\n","    sys.stdout.write(text)\n","    sys.stdout.flush()\n","\n","'''\n","runs = 300\n","for run_num in range(runs):\n","    time.sleep(.1)\n","    updt(runs, run_num + 1)\n","'''"],"execution_count":147,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nruns = 300\\nfor run_num in range(runs):\\n    time.sleep(.1)\\n    updt(runs, run_num + 1)\\n'"]},"metadata":{"tags":[]},"execution_count":147}]},{"cell_type":"code","metadata":{"id":"_Eo8c-aRJ7Ev"},"source":["setDuplicate = set()\n","# parentNodeInfo = None\n","def dictAssign(tempDict, key, item):\n","  # print(f\"{tempDict}\")\n","  # print(f\"{key}\")\n","  # print(f\"{item}\")\n","  global setDuplicate\n","  # global parentNodeInfo\n","\n","  #if duplicate\n","  if(key in tempDict.keys()):\n","    if(tempDict[key]):\n","      setDuplicate.add(key)\n","      # print(parentNodeInfo)\n","      if(type(tempDict[key]) is list):\n","        tempDict[key].append(item)\n","      else:\n","        firstValue = tempDict[key]\n","        tempDict[key] = [firstValue]\n","        tempDict[key].append(item)\n","    else:\n","      #first time, not duplicate\n","      tempDict[key] = item\n","  else:\n","    tempDict[key] = item\n","\n","  return tempDict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ZkOPodHPmWE","executionInfo":{"status":"ok","timestamp":1626838401117,"user_tz":240,"elapsed":191,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}}},"source":["\n","\n","\n","\n","def showInfo(root):\n","  \n","  test = 0\n","  listColumns = ['fileobject_id']\n","  df = pd.DataFrame(columns=listColumns)\n","  fileobjects = root.findall('.//{http://www.forensicswiki.org/wiki/Category:Digital_Forensics_XML}fileobject')\n","  for fileobject_id, fileobject in enumerate(fileobjects):\n","    tempDict = {}\n","    # tempDict['fileobject_id'] = fileobject_id\n","    tempDict = dictAssign(tempDict,\"fileobject_id\",fileobject_id)\n","    for node in fileobject.iter():\n","      # global parentNodeInfo\n","      # if(node.getparent()):\n","      #   parentNodeInfo = node.getparent().tag\n","      # if(mode == 'test'):\n","      #   pass\n","        # if(test < 1):\n","        #   print(f\"id: {fileobject_id}, tag: {rename(node.tag)}\")\n","        #   print(f\"id: {fileobject_id}, text: {node.text}\")\n","        #   print(f\"id: {fileobject_id}, attributes: {node.attrib}\")\n","      # print(rename(node.tag))\n","      # tempDict[rename(node.tag)] = node.text\n","      tempDict = dictAssign(tempDict,rename(node.tag),node.text)\n","\n","      # tempDict['attrib'] = node.attrib\n","      if(node.attrib): #if the attrib exists\n","        for key, item in node.attrib.items():\n","          # print(f\"attrib: key: {key}, item: {item}\")\n","          tempDict = dictAssign(tempDict,rename(key),item)\n","          # tempDict[rename(key)] = item\n","    df = df.append(tempDict, \n","              ignore_index=True)\n","\n","\n","    test+=1\n","\n","    updt(len(fileobjects), fileobject_id + 1)\n","    if(mode == 'test'):\n","      if(test>2):\n","        print(f\"fileobject 0 ~ {fileobject_id} is done. Then break...\")\n","        break\n","\n","  return df\n","      \n","      \n","\n"],"execution_count":160,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfxu3ezyN93Z","executionInfo":{"status":"ok","timestamp":1626838406481,"user_tz":240,"elapsed":2663,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}},"outputId":"74c28eab-1d58-44a0-d241-4f98b1c83acc"},"source":["test = 0\n","for eachFile in glob.glob(f\"{pathToDxml}/*.dfxml\"):\n","  print(f\"parsing {eachFile} ...\")\n","  # if (os.path.exists(f\"{pathToDxml}/parse_result_{os.path.basename(eachFile)[:-6]}.csv\")):\n","  #   print(f\"{pathToDxml}/parse_result_{os.path.basename(eachFile)[:-6]}.csv exists, move to next dfxml file.\")\n","  #   continue\n","  \n","  # print(f\"size (bytes): {os.path.getsize(eachFile)}\")\n","  # print(f\"basename (no extention): {os.path.basename(eachFile)[:-6]}\")\n","  parseDxml(eachFile)\n","  test+=1\n","  if(mode == \"test\"):\n","    if(test==0):\n","      break\n","print(f\"the following columns has duplicated values: {setDuplicate}\")\n","print(f\"value of the len(setDuplicate): {len(setDuplicate)}\")"],"execution_count":161,"outputs":[{"output_type":"stream","text":["parsing /content/drive/MyDrive/security_mft/dfxml_files/fourth_fifth.dfxml ...\n","[--------------------] 1% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for fourth_fifth: 0:00:00.055884\n","parsing /content/drive/MyDrive/security_mft/dfxml_files/sixth_seventh.dfxml ...\n","[--------------------] 0% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for sixth_seventh: 0:00:00.579759\n","parsing /content/drive/MyDrive/security_mft/dfxml_files/second_third.dfxml ...\n","[--------------------] 0% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for second_third: 0:00:00.237946\n","parsing /content/drive/MyDrive/security_mft/dfxml_files/first_second.dfxml ...\n","[--------------------] 0% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for first_second: 0:00:00.477721\n","parsing /content/drive/MyDrive/security_mft/dfxml_files/fifth_sixth.dfxml ...\n","[--------------------] 0% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for fifth_sixth: 0:00:00.752172\n","parsing /content/drive/MyDrive/security_mft/dfxml_files/third_fourth.dfxml ...\n","[--------------------] 0% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for third_fourth: 0:00:00.338673\n","the following columns has duplicated values: {'id', 'mode', 'type', 'crtime', 'nlink', 'atime', 'partition', 'mtime', 'seq', 'len', 'img_offset', 'filename', 'changed_property', 'gid', 'hashdigest', 'meta_type', 'alloc', 'name_type', 'fs_offset', 'inode', 'file_offset', 'used', 'ctime', 'filesize', 'uid'}\n","value of the len(setDuplicate): 25\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eqo4sYlxQXzL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626838408053,"user_tz":240,"elapsed":279,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}},"outputId":"fb9c2ab1-740c-47e8-e083-b3cfff1f29f0"},"source":["pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","if(mode == \"test\"):\n","  filepath = glob.glob(f\"{pathToDxml}/parse_result_fourth_fifth.csv\")[0]#\"/content/drive/MyDrive/security_mft/dfxml_files/parse_result_fourth_fifth.csv\"\n","else:\n","  filepath = glob.glob(f\"{pathToDxml}/*.csv\")[0]#\"/content/drive/MyDrive/security_mft/dfxml_files/parse_result_fourth_fifth.csv\"\n","print(filepath)\n","df = pd.read_csv(filepath)\n","print(f\"How many columns: {len(df.columns)}\")\n","print(f\"column names: {df.columns}\")\n","print(df.head(50))"],"execution_count":162,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/security_mft/dfxml_files/parse_result_fourth_fifth.csv\n","How many columns: 34\n","column names: Index(['fileobject_id', 'alloc', 'atime', 'byte_run', 'byte_runs', 'crtime',\n","       'ctime', 'file_offset', 'filename', 'fileobject', 'filesize',\n","       'fs_offset', 'gid', 'hashdigest', 'id', 'img_offset', 'inode', 'len',\n","       'meta_type', 'mode', 'mtime', 'name_type', 'new_file', 'nlink',\n","       'parent_object', 'partition', 'seq', 'type', 'uid', 'used',\n","       'changed_file', 'changed_property', 'deleted_file',\n","       'original_fileobject'],\n","      dtype='object')\n","   fileobject_id       alloc  \\\n","0              0           0   \n","1              1  ['0', '1']   \n","2              2  ['0', '1']   \n","\n","                                              atime  byte_run  byte_runs  \\\n","0                              2021-06-06T20:07:19Z       NaN        NaN   \n","1  ['2021-06-06T20:11:52Z', '2021-06-06T20:11:52Z']       NaN        NaN   \n","2  ['2021-06-06T20:11:52Z', '2021-06-06T20:11:52Z']       NaN        NaN   \n","\n","                                             crtime  \\\n","0                              2021-06-06T20:07:19Z   \n","1  ['2021-06-06T20:11:52Z', '2021-06-06T20:11:52Z']   \n","2  ['2021-06-06T20:11:52Z', '2021-06-06T20:11:52Z']   \n","\n","                                              ctime file_offset  \\\n","0                              2021-06-06T20:07:21Z           0   \n","1  ['2021-06-06T20:11:52Z', '2021-06-06T20:11:52Z']  ['0', '0']   \n","2  ['2021-06-06T20:11:52Z', '2021-06-06T20:11:52Z']  ['0', '0']   \n","\n","                                            filename  fileobject  \\\n","0            Windows/System32/spp/store/2.0/data.dat         NaN   \n","1  ['$Recycle.Bin/S-1-5-21-2194026162-3461440824-...         NaN   \n","2  ['$Recycle.Bin/S-1-5-21-2194026162-3461440824-...         NaN   \n","\n","       filesize   fs_offset         gid  \\\n","0          6208   526270464           0   \n","1  ['94', '94']  ['0', '0']  ['0', '0']   \n","2  ['96', '96']  ['0', '0']  ['0', '0']   \n","\n","                                          hashdigest            id  \\\n","0  ['39708a9883e196de5011243eef13c923', '9b3e16d4...         42175   \n","1  ['a38eb597b3888279dc4c8fcaae29b0d9', '529f7bf5...  ['39', '49']   \n","2  ['2f79145fd24800d20f390db9382eaef2', '2b9f92de...  ['40', '40']   \n","\n","               img_offset                                 inode           len  \\\n","0               527319040                     ['4366', '95392']          6208   \n","1  ['1048576', '1048576']  ['92206', '89297', '92206', '89297']  ['94', '94']   \n","2  ['1048576', '1048576']  ['92206', '89387', '92206', '89387']  ['96', '96']   \n","\n","    meta_type            mode  \\\n","0           1             365   \n","1  ['1', '1']  ['511', '511']   \n","2  ['1', '1']  ['511', '511']   \n","\n","                                              mtime   name_type  new_file  \\\n","0                              2021-06-06T20:07:19Z           -       1.0   \n","1  ['2021-06-06T20:11:52Z', '2021-06-06T20:11:52Z']  ['-', 'r']       NaN   \n","2  ['2021-06-06T20:11:52Z', '2021-06-06T20:11:52Z']  ['-', 'r']       NaN   \n","\n","        nlink  parent_object   partition         seq  \\\n","0           1            NaN           1           7   \n","1  ['1', '1']            NaN  ['1', '1']  ['5', '4']   \n","2  ['1', '1']            NaN  ['1', '1']  ['4', '3']   \n","\n","                                                type         uid        used  \\\n","0                                    ['md5', 'sha1']           0           1   \n","1  ['resident', 'md5', 'sha1', 'resident', 'md5',...  ['0', '0']  ['1', '1']   \n","2  ['resident', 'md5', 'sha1', 'resident', 'md5',...  ['0', '0']  ['1', '1']   \n","\n","   changed_file changed_property  deleted_file  original_fileobject  \n","0           NaN              NaN           NaN                  NaN  \n","1           1.0  ['1', '1', '1']           1.0                  NaN  \n","2           1.0  ['1', '1', '1']           1.0                  NaN  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jn76ENptPLwr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626837524934,"user_tz":240,"elapsed":13,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}},"outputId":"6346207b-8bd0-4d22-8c20-9b53275cfdd5"},"source":["end_time_total = datetime.now()\n","print('Duration of finishing parsing all dfxml files: {}'.format(end_time_total - start_time))"],"execution_count":151,"outputs":[{"output_type":"stream","text":["Duration of finishing parsing all dfxml files: 0:00:02.692491\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oKNP8qd7IEwV"},"source":["# Method 2: lxml (can access parent node)"]},{"cell_type":"code","metadata":{"id":"FJdroKgDIG57","executionInfo":{"status":"ok","timestamp":1626840039020,"user_tz":240,"elapsed":172,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}}},"source":["from lxml import etree\n"],"execution_count":188,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDbE5Y0NIe0Q","executionInfo":{"status":"ok","timestamp":1626840042839,"user_tz":240,"elapsed":167,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}}},"source":["def parseDxml_lxml(pathToFile):\n","  start_time = datetime.now()\n","\n","  tree = etree.parse(pathToFile)\n","  root = tree.getroot()\n","  df = showInfo_lxml(root)\n","\n","  csv_filename = f\"{pathToDxml}/parse_result_{os.path.basename(pathToFile)[:-6]}.csv\"\n","  df.to_csv (csv_filename, index = False, header=True)\n","\n","  end_time = datetime.now()\n","  print(f\"Duration of parsing data for {os.path.basename(pathToFile)[:-6]}: {end_time - start_time}\")"],"execution_count":190,"outputs":[]},{"cell_type":"code","metadata":{"id":"byJ_uwi2J-t0","executionInfo":{"status":"ok","timestamp":1626840169893,"user_tz":240,"elapsed":177,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}}},"source":["setDuplicate = set()\n","parentNodeInfo = dict()\n","def dictAssign(tempDict, key, item):\n","  # print(f\"{tempDict}\")\n","  # print(f\"{key}\")\n","  # print(f\"{item}\")\n","  global setDuplicate\n","  global parentNodeInfo\n","\n","  #if duplicate\n","  if(key in tempDict.keys()):\n","    if(tempDict[key]):\n","      setDuplicate.add(key)\n","      # print(parentNodeInfo)\n","      strFirst = f\"{key}_{parentNodeInfo[key]}\"\n","      strSpecify = f\"{key}_{parentNodeInfo[key]}\"\n","      # tempDict[strFirst] = tempDict[key]\n","      tempDict[strSpecify] = item\n","\n","      '''\n","      #store to a list\n","      if(type(tempDict[key]) is list):\n","        tempDict[key].append(item)\n","        strFirst = f\"{key}_first\"\n","        strSpecify = f\"{key}_{parentNodeInfo}\"\n","        tempDict[strFirst] = tempDict[key][0]\n","        tempDict[strSpecify] = item\n","      else:\n","        firstValue = tempDict[key]\n","        tempDict[key] = [firstValue]\n","        tempDict[key].append(item)\n","      '''\n","    else:\n","      #first time, not duplicate\n","      tempDict[key] = item\n","  else:\n","    tempDict[key] = item\n","\n","  return tempDict"],"execution_count":192,"outputs":[]},{"cell_type":"code","metadata":{"id":"ilW_VlI_KJ1c","executionInfo":{"status":"ok","timestamp":1626840173579,"user_tz":240,"elapsed":519,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}}},"source":["\n","\n","\n","\n","def showInfo_lxml(root):\n","  \n","  test = 0\n","  listColumns = ['fileobject_id']\n","  df = pd.DataFrame(columns=listColumns)\n","  fileobjects = root.findall('.//{http://www.forensicswiki.org/wiki/Category:Digital_Forensics_XML}fileobject')\n","  for fileobject_id, fileobject in enumerate(fileobjects):\n","    tempDict = {}\n","    # tempDict['fileobject_id'] = fileobject_id\n","    tempDict = dictAssign(tempDict,\"fileobject_id\",fileobject_id)\n","    for node in fileobject.iter():\n","      global parentNodeInfo\n","      if(node.getparent()):\n","        # if(key in tempDict.keys())\n","        parentNodeInfo[rename(node.tag)] = rename(node.getparent().tag)\n","      else:\n","        parentNodeInfo[rename(node.tag)] = None\n","\n","      # if(mode == 'test'):\n","      #   pass\n","        # if(test < 1):\n","        #   print(f\"id: {fileobject_id}, tag: {rename(node.tag)}\")\n","        #   print(f\"id: {fileobject_id}, text: {node.text}\")\n","        #   print(f\"id: {fileobject_id}, attributes: {node.attrib}\")\n","      # print(rename(node.tag))\n","      # tempDict[rename(node.tag)] = node.text\n","      tempDict = dictAssign(tempDict,rename(node.tag),node.text)\n","\n","      # tempDict['attrib'] = node.attrib\n","      if(node.attrib): #if the attrib exists\n","        for key, item in node.attrib.items():\n","          # print(f\"attrib: key: {key}, item: {item}\")\n","          tempDict = dictAssign(tempDict,rename(key),item)\n","          # tempDict[rename(key)] = item\n","    df = df.append(tempDict, \n","              ignore_index=True)\n","\n","\n","    test+=1\n","\n","    updt(len(fileobjects), fileobject_id + 1)\n","    if(mode == 'test'):\n","      if(test>2):\n","        print(f\"fileobject 0 ~ {fileobject_id} is done. Then break...\")\n","        break\n","\n","  return df\n","      \n","      \n","\n"],"execution_count":193,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UvsYIRRCJqU0","executionInfo":{"status":"ok","timestamp":1626840176434,"user_tz":240,"elapsed":1182,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}},"outputId":"9804cc12-9b0a-424a-8a98-54c0a69a120c"},"source":["test = 0\n","for eachFile in glob.glob(f\"{pathToDxml}/*.dfxml\"):\n","  print(f\"parsing {eachFile} ...\")\n","  # if (os.path.exists(f\"{pathToDxml}/parse_result_{os.path.basename(eachFile)[:-6]}.csv\")):\n","  #   print(f\"{pathToDxml}/parse_result_{os.path.basename(eachFile)[:-6]}.csv exists, move to next dfxml file.\")\n","  #   continue\n","  \n","  # print(f\"size (bytes): {os.path.getsize(eachFile)}\")\n","  # print(f\"basename (no extention): {os.path.basename(eachFile)[:-6]}\")\n","  parseDxml_lxml(eachFile)\n","  test+=1\n","  if(mode == \"test\"):\n","    if(test==0):\n","      break\n","print(f\"the following columns has duplicated values: {setDuplicate}\")\n","print(f\"value of the len(setDuplicate): {len(setDuplicate)}\")"],"execution_count":194,"outputs":[{"output_type":"stream","text":["parsing /content/drive/MyDrive/security_mft/dfxml_files/fourth_fifth.dfxml ...\n","[--------------------] 1% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for fourth_fifth: 0:00:00.058678\n","parsing /content/drive/MyDrive/security_mft/dfxml_files/sixth_seventh.dfxml ...\n","[--------------------] 0% "],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n"],"name":"stderr"},{"output_type":"stream","text":["[--------------------] 0% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for sixth_seventh: 0:00:00.179903\n","parsing /content/drive/MyDrive/security_mft/dfxml_files/second_third.dfxml ...\n","[--------------------] 0% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for second_third: 0:00:00.099606\n","parsing /content/drive/MyDrive/security_mft/dfxml_files/first_second.dfxml ...\n","[--------------------] 0% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for first_second: 0:00:00.132036\n","parsing /content/drive/MyDrive/security_mft/dfxml_files/fifth_sixth.dfxml ...\n","[--------------------] 0% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for fifth_sixth: 0:00:00.288031\n","parsing /content/drive/MyDrive/security_mft/dfxml_files/third_fourth.dfxml ...\n","[--------------------] 0% fileobject 0 ~ 2 is done. Then break...\n","Duration of parsing data for third_fourth: 0:00:00.117707\n","the following columns has duplicated values: {'id', 'mode', 'type', 'crtime', 'nlink', 'atime', 'partition', 'mtime', 'seq', 'len', 'img_offset', 'filename', 'changed_property', 'gid', 'hashdigest', 'meta_type', 'alloc', 'name_type', 'fs_offset', 'inode', 'file_offset', 'used', 'ctime', 'filesize', 'uid'}\n","value of the len(setDuplicate): 25\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rc94oVRIJuOT","executionInfo":{"status":"ok","timestamp":1626840180210,"user_tz":240,"elapsed":179,"user":{"displayName":"Xiaxin Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmacjeCpHUXUw-8YYHOaPMIwu5j1NTe89ui6zP=s64","userId":"02942036663319565536"}},"outputId":"58d59273-a9bc-4410-fe61-d3621546a2c5"},"source":["pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","if(mode == \"test\"):\n","  filepath = glob.glob(f\"{pathToDxml}/parse_result_fourth_fifth.csv\")[0]#\"/content/drive/MyDrive/security_mft/dfxml_files/parse_result_fourth_fifth.csv\"\n","else:\n","  filepath = glob.glob(f\"{pathToDxml}/*.csv\")[0]#\"/content/drive/MyDrive/security_mft/dfxml_files/parse_result_fourth_fifth.csv\"\n","print(filepath)\n","df = pd.read_csv(filepath)\n","print(f\"How many columns: {len(df.columns)}\")\n","print(f\"column names: {df.columns}\")\n","print(df.head(50))"],"execution_count":195,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/security_mft/dfxml_files/parse_result_fourth_fifth.csv\n","How many columns: 64\n","column names: Index(['fileobject_id', 'alloc', 'atime', 'byte_run', 'byte_runs', 'crtime',\n","       'ctime', 'file_offset', 'filename', 'fileobject', 'filesize',\n","       'fs_offset', 'gid', 'hashdigest', 'hashdigest_fileobject', 'id',\n","       'img_offset', 'inode', 'inode_fileobject', 'len', 'meta_type', 'mode',\n","       'mtime', 'name_type', 'new_file', 'nlink', 'parent_object', 'partition',\n","       'seq', 'type', 'type_fileobject', 'uid', 'used',\n","       'alloc_original_fileobject', 'atime_original_fileobject',\n","       'changed_file', 'changed_property', 'changed_property_fileobject',\n","       'crtime_original_fileobject', 'ctime_original_fileobject',\n","       'deleted_file', 'file_offset_byte_runs', 'filename_original_fileobject',\n","       'filesize_original_fileobject', 'fs_offset_byte_runs',\n","       'gid_original_fileobject', 'hashdigest_original_fileobject',\n","       'id_original_fileobject', 'img_offset_byte_runs',\n","       'inode_original_fileobject', 'inode_parent_object', 'len_byte_runs',\n","       'meta_type_original_fileobject', 'mode_original_fileobject',\n","       'mtime_original_fileobject', 'name_type_original_fileobject',\n","       'nlink_original_fileobject', 'original_fileobject',\n","       'partition_original_fileobject', 'seq_original_fileobject',\n","       'type_byte_runs', 'type_original_fileobject', 'uid_original_fileobject',\n","       'used_original_fileobject'],\n","      dtype='object')\n","   fileobject_id  alloc                 atime  byte_run  byte_runs  \\\n","0              0      0  2021-06-06T20:07:19Z       NaN        NaN   \n","1              1      0  2021-06-06T20:11:52Z       NaN        NaN   \n","2              2      0  2021-06-06T20:11:52Z       NaN        NaN   \n","\n","                 crtime                 ctime  file_offset  \\\n","0  2021-06-06T20:07:19Z  2021-06-06T20:07:21Z            0   \n","1  2021-06-06T20:11:52Z  2021-06-06T20:11:52Z            0   \n","2  2021-06-06T20:11:52Z  2021-06-06T20:11:52Z            0   \n","\n","                                            filename  fileobject  filesize  \\\n","0            Windows/System32/spp/store/2.0/data.dat         NaN      6208   \n","1  $Recycle.Bin/S-1-5-21-2194026162-3461440824-22...         NaN        94   \n","2  $Recycle.Bin/S-1-5-21-2194026162-3461440824-22...         NaN        96   \n","\n","   fs_offset  gid                        hashdigest  \\\n","0  526270464    0  39708a9883e196de5011243eef13c923   \n","1          0    0  a38eb597b3888279dc4c8fcaae29b0d9   \n","2          0    0  2f79145fd24800d20f390db9382eaef2   \n","\n","                      hashdigest_fileobject     id  img_offset  inode  \\\n","0  9b3e16d460d4c324bf82853216961a0c7a705c52  42175   527319040   4366   \n","1  529f7bf55f4c6cf28baa951700a00bb0b6960843     39     1048576  92206   \n","2  2b9f92dedb738f78a7515ce57a4d4508d5462677     40     1048576  92206   \n","\n","   inode_fileobject   len  meta_type  mode                 mtime name_type  \\\n","0             95392  6208          1   365  2021-06-06T20:07:19Z         -   \n","1             89297    94          1   511  2021-06-06T20:11:52Z         -   \n","2             89387    96          1   511  2021-06-06T20:11:52Z         -   \n","\n","   new_file  nlink  parent_object  partition  seq      type type_fileobject  \\\n","0       1.0      1            NaN          1    7       md5            sha1   \n","1       NaN      1            NaN          1    5  resident            sha1   \n","2       NaN      1            NaN          1    4  resident            sha1   \n","\n","   uid  used  alloc_original_fileobject atime_original_fileobject  \\\n","0    0     1                        NaN                       NaN   \n","1    0     1                        1.0      2021-06-06T20:11:52Z   \n","2    0     1                        1.0      2021-06-06T20:11:52Z   \n","\n","   changed_file  changed_property  changed_property_fileobject  \\\n","0           NaN               NaN                          NaN   \n","1           1.0               1.0                          1.0   \n","2           1.0               1.0                          1.0   \n","\n","  crtime_original_fileobject ctime_original_fileobject  deleted_file  \\\n","0                        NaN                       NaN           NaN   \n","1       2021-06-06T20:11:52Z      2021-06-06T20:11:52Z           1.0   \n","2       2021-06-06T20:11:52Z      2021-06-06T20:11:52Z           1.0   \n","\n","   file_offset_byte_runs                       filename_original_fileobject  \\\n","0                    NaN                                                NaN   \n","1                    0.0  $Recycle.Bin/S-1-5-21-2194026162-3461440824-22...   \n","2                    0.0  $Recycle.Bin/S-1-5-21-2194026162-3461440824-22...   \n","\n","   filesize_original_fileobject  fs_offset_byte_runs  gid_original_fileobject  \\\n","0                           NaN                  NaN                      NaN   \n","1                          94.0                  0.0                      0.0   \n","2                          96.0                  0.0                      0.0   \n","\n","             hashdigest_original_fileobject  id_original_fileobject  \\\n","0                                       NaN                     NaN   \n","1  529f7bf55f4c6cf28baa951700a00bb0b6960843                    49.0   \n","2  2b9f92dedb738f78a7515ce57a4d4508d5462677                    40.0   \n","\n","   img_offset_byte_runs  inode_original_fileobject  inode_parent_object  \\\n","0                   NaN                        NaN                  NaN   \n","1             1048576.0                    89297.0              92206.0   \n","2             1048576.0                    89387.0              92206.0   \n","\n","   len_byte_runs  meta_type_original_fileobject  mode_original_fileobject  \\\n","0            NaN                            NaN                       NaN   \n","1           94.0                            1.0                     511.0   \n","2           96.0                            1.0                     511.0   \n","\n","  mtime_original_fileobject name_type_original_fileobject  \\\n","0                       NaN                           NaN   \n","1      2021-06-06T20:11:52Z                             r   \n","2      2021-06-06T20:11:52Z                             r   \n","\n","   nlink_original_fileobject  original_fileobject  \\\n","0                        NaN                  NaN   \n","1                        1.0                  NaN   \n","2                        1.0                  NaN   \n","\n","   partition_original_fileobject  seq_original_fileobject type_byte_runs  \\\n","0                            NaN                      NaN            NaN   \n","1                            1.0                      4.0       resident   \n","2                            1.0                      3.0       resident   \n","\n","  type_original_fileobject  uid_original_fileobject  used_original_fileobject  \n","0                      NaN                      NaN                       NaN  \n","1                     sha1                      0.0                       1.0  \n","2                     sha1                      0.0                       1.0  \n"],"name":"stdout"}]}]}